{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Conv2D, Add, ZeroPadding2D, UpSampling2D, Concatenate, MaxPooling2D, LeakyReLU, BatchNormalization, Input, Lambda\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from PIL import Image\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose(*funcs):\n",
    "    \"\"\"Compose arbitrarily many functions, evaluated left to right.\n",
    "\n",
    "    Reference: https://mathieularose.com/function-composition-in-python/\n",
    "    \"\"\"\n",
    "    # return lambda x: reduce(lambda v, f: f(v), funcs, x)\n",
    "    if funcs:\n",
    "        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)\n",
    "    else:\n",
    "        raise ValueError('Composition of empty sequence not supported.')\n",
    "        \n",
    "#依次执行参数对应的函数操作 简化代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DarknetConv2D(*args, **kwargs):\n",
    "    \"\"\"Wrapper to set Darknet parameters for Convolution2D.\"\"\"\n",
    "    darknet_conv_kwargs = {'kernel_regularizer': l2(5e-4)} #正则化\n",
    "    darknet_conv_kwargs['padding'] = 'valid' if kwargs.get('strides') == (2, 2) else 'same' #加边\n",
    "    darknet_conv_kwargs.update(kwargs) #更新参数\n",
    "    return Conv2D(*args, **darknet_conv_kwargs)\n",
    "\n",
    "\n",
    "def DarknetConv2D_BN_Leaky(*args, **kwargs):\n",
    "    \"\"\"Darknet Convolution2D followed by BatchNormalization and LeakyReLU.\"\"\"\n",
    "    no_bias_kwargs = {'use_bias': False}\n",
    "    no_bias_kwargs.update(kwargs)\n",
    "    return compose(\n",
    "        DarknetConv2D(*args, **no_bias_kwargs),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1))\n",
    "#卷积+BN+激活\n",
    "\n",
    "def resblock_body(x, num_filters, num_blocks):\n",
    "    '''A series of resblocks starting with a downsampling Convolution2D'''\n",
    "    # Darknet uses left and top padding instead of 'same' mode\n",
    "    x = ZeroPadding2D(((1, 0), (1, 0)))(x)\n",
    "    x = DarknetConv2D_BN_Leaky(num_filters, (3, 3), strides=(2, 2))(x)\n",
    "    for i in range(num_blocks):\n",
    "        y = compose(\n",
    "            DarknetConv2D_BN_Leaky(num_filters // 2, (1, 1)),\n",
    "            DarknetConv2D_BN_Leaky(num_filters, (3, 3)))(x)\n",
    "        x = Add()([x, y])\n",
    "    return x\n",
    "#加边+卷积模块+拼接\n",
    "\n",
    "def darknet_body(x):\n",
    "    '''Darknent body having 52 Convolution2D layers'''\n",
    "    x = DarknetConv2D_BN_Leaky(32, (3, 3))(x)\n",
    "    x = resblock_body(x, 64, 1)\n",
    "    x = resblock_body(x, 128, 2)\n",
    "    x = resblock_body(x, 256, 8)\n",
    "    x = resblock_body(x, 512, 8)\n",
    "    x = resblock_body(x, 1024, 4)\n",
    "    return x\n",
    "\n",
    "#卷积部分\n",
    "\n",
    "def make_last_layers(x, num_filters, out_filters):\n",
    "    '''6 Conv2D_BN_Leaky layers followed by a Conv2D_linear layer'''\n",
    "    x = compose(\n",
    "        DarknetConv2D_BN_Leaky(num_filters, (1, 1)),\n",
    "        DarknetConv2D_BN_Leaky(num_filters * 2, (3, 3)),\n",
    "        DarknetConv2D_BN_Leaky(num_filters, (1, 1)),\n",
    "        DarknetConv2D_BN_Leaky(num_filters * 2, (3, 3)),\n",
    "        DarknetConv2D_BN_Leaky(num_filters, (1, 1)))(x)\n",
    "    y = compose(\n",
    "        DarknetConv2D_BN_Leaky(num_filters * 2, (3, 3)),\n",
    "        DarknetConv2D(out_filters, (1, 1)))(x)\n",
    "    return x, y\n",
    "\n",
    "#输出部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_body(inputs, num_anchors, num_classes):\n",
    "    \"\"\"创建 YOLOv3 模型的主体\n",
    "    - inputs: 模型输入\n",
    "    - num_anchors: 每个尺度的锚点数量\n",
    "    - num_classes: 类别数量\n",
    "    \"\"\"\n",
    "\n",
    "    # 创建 Darknet 主体网络\n",
    "    darknet = Model(inputs, darknet_body(inputs))\n",
    "\n",
    "    # 构建模型的最后几层并获取第一个尺度的输出\n",
    "    x, y1 = make_last_layers(darknet.output, 512, num_anchors * (num_classes + 5))\n",
    "\n",
    "    # 上采样并与前一层的输出进行连接\n",
    "    x = compose(\n",
    "        DarknetConv2D_BN_Leaky(256, (1, 1)),\n",
    "        UpSampling2D(2))(x)\n",
    "    x = Concatenate()([x, darknet.layers[152].output])\n",
    "    # 构建模型的第二个尺度的输出\n",
    "    x, y2 = make_last_layers(x, 256, num_anchors * (num_classes + 5))\n",
    "\n",
    "    # 再次上采样并与前一层的输出进行连接\n",
    "    x = compose(\n",
    "        DarknetConv2D_BN_Leaky(128, (1, 1)),\n",
    "        UpSampling2D(2))(x)\n",
    "    x = Concatenate()([x, darknet.layers[92].output])\n",
    "    # 构建模型的第三个尺度的输出\n",
    "    x, y3 = make_last_layers(x, 128, num_anchors * (num_classes + 5))\n",
    "\n",
    "    # 返回包含三个尺度输出的模型\n",
    "    return Model(inputs, [y1, y2, y3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_head(feats, anchors, num_classes, input_shape, calc_loss=False):\n",
    "    \"\"\"Convert final layer features to bounding box parameters.\n",
    "    - feats: 特征图，模型最后一层的输出\n",
    "    - anchors: 锚点数组，定义了一系列预设的边界框尺寸\n",
    "    - num_classes: 目标类别总数\n",
    "    - input_shape: 输入尺寸\n",
    "    - calc_loss: 是否用于损失计算\n",
    "    \"\"\"\n",
    "\n",
    "    # 计算锚点数量\n",
    "    num_anchors = len(anchors)\n",
    "    # 将锚点数据转换为 Keras 张量\n",
    "    anchors_tensor = K.reshape(K.constant(anchors), [1, 1, 1, num_anchors, 2])\n",
    "\n",
    "    # 获取特征图的高度和宽度\n",
    "    grid_shape = K.shape(feats)[1:3]  # height, width\n",
    "    # 生成网格坐标\n",
    "    grid_y = K.tile(K.reshape(K.arange(0, stop=grid_shape[0]), [-1, 1, 1, 1]),[1, grid_shape[1], 1, 1])\n",
    "    grid_x = K.tile(K.reshape(K.arange(0, stop=grid_shape[1]), [1, -1, 1, 1]),[grid_shape[0], 1, 1, 1])\n",
    "    grid = K.concatenate([grid_x, grid_y])\n",
    "    grid = K.cast(grid, K.dtype(feats))\n",
    "\n",
    "    # 重塑特征图以适应边界框的形状\n",
    "    feats = K.reshape(feats, [-1, grid_shape[0], grid_shape[1], num_anchors, num_classes + 5])\n",
    "\n",
    "    # 调整预测结果到每个空间网格点和锚点尺寸\n",
    "    box_xy = (K.sigmoid(feats[..., :2]) + grid) / K.cast(grid_shape[::-1], K.dtype(feats))\n",
    "    box_wh = K.exp(feats[..., 2:4]) * anchors_tensor / K.cast(input_shape[::-1], K.dtype(feats))\n",
    "    box_confidence = K.sigmoid(feats[..., 4:5])\n",
    "    box_class_probs = K.sigmoid(feats[..., 5:])\n",
    "\n",
    "    # 如果用于损失计算，返回网格和各种调整后的预测值\n",
    "    if calc_loss == True:\n",
    "        return grid, feats, box_xy, box_wh\n",
    "    # 否则，返回边界框的坐标、尺寸、置信度和类别概率\n",
    "    return box_xy, box_wh, box_confidence, box_class_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_iou(b1, b2):\n",
    "    \"\"\"\n",
    "    Return IoU tensor\n",
    "    Parameters:\n",
    "    - b1: tensor, shape=(i1,...,iN, 4), xywh  # 预测边界框\n",
    "    - b2: tensor, shape=(j, 4), xywh          # 真实边界框\n",
    "    Returns:\n",
    "    - iou: tensor, shape=(i1,...,iN, j)       # IoU值\n",
    "    \"\"\"\n",
    "\n",
    "    # 对第一组边界框进行扩展，以便进行广播运算\n",
    "    b1 = K.expand_dims(b1, -2)\n",
    "    # 提取中心点坐标和尺寸\n",
    "    b1_xy = b1[..., :2]\n",
    "    b1_wh = b1[..., 2:4]\n",
    "    # 计算边界框的左上角和右下角坐标\n",
    "    b1_wh_half = b1_wh / 2.\n",
    "    b1_mins = b1_xy - b1_wh_half\n",
    "    b1_maxes = b1_xy + b1_wh_half\n",
    "\n",
    "    # 对第二组边界框进行类似处理\n",
    "    b2 = K.expand_dims(b2, 0)\n",
    "    b2_xy = b2[..., :2]\n",
    "    b2_wh = b2[..., 2:4]\n",
    "    b2_wh_half = b2_wh / 2.\n",
    "    b2_mins = b2_xy - b2_wh_half\n",
    "    b2_maxes = b2_xy + b2_wh_half\n",
    "\n",
    "    # 计算两组边界框交集的坐标\n",
    "    intersect_mins = K.maximum(b1_mins, b2_mins)\n",
    "    intersect_maxes = K.minimum(b1_maxes, b2_maxes)\n",
    "    intersect_wh = K.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    # 计算交集区域的面积\n",
    "    intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    # 计算每组边界框的面积\n",
    "    b1_area = b1_wh[..., 0] * b1_wh[..., 1]\n",
    "    b2_area = b2_wh[..., 0] * b2_wh[..., 1]\n",
    "    # 计算IoU值\n",
    "    iou = intersect_area / (b1_area + b2_area - intersect_area)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_loss(args, anchors, num_classes, ignore_thresh=.5, print_loss=False):\n",
    "    \"\"\"\n",
    "    计算 YOLO 损失\n",
    "    Parameters:\n",
    "    - args: 输入参数，包括 yolo_outputs 和 y_true\n",
    "    - anchors: 锚点尺寸\n",
    "    - num_classes: 类别数\n",
    "    - ignore_thresh: 忽略阈值，用于过滤某些预测框\n",
    "    - print_loss: 是否打印损失信息\n",
    "    Returns:\n",
    "    - loss: 计算得到的损失值\n",
    "    \"\"\"\n",
    "\n",
    "    # 计算层数\n",
    "    num_layers = len(anchors) // 3  # 默认设置\n",
    "    # 获取 YOLO 输出和真实标签\n",
    "    yolo_outputs = args[:num_layers]\n",
    "    y_true = args[num_layers:]\n",
    "    # 定义每层使用的锚点\n",
    "    anchor_mask = [[6, 7, 8], [3, 4, 5], [0, 1, 2]] if num_layers == 3 else [[3, 4, 5], [1, 2, 3]]\n",
    "\n",
    "    # 计算输入尺寸和网格尺寸\n",
    "    input_shape = K.cast(K.shape(yolo_outputs[0])[1:3] * 32, K.dtype(y_true[0]))\n",
    "    grid_shapes = [K.cast(K.shape(yolo_outputs[l])[1:3], K.dtype(y_true[0])) for l in range(num_layers)]\n",
    "\n",
    "    # 初始化损失\n",
    "    loss = 0\n",
    "    # 获取批次大小\n",
    "    m = K.shape(yolo_outputs[0])[0]  # batch size, tensor\n",
    "    # 批次大小转换为浮点型\n",
    "    mf = K.cast(m, K.dtype(yolo_outputs[0]))\n",
    "\n",
    "    # 遍历每层\n",
    "    for l in range(num_layers):\n",
    "        # 提取对象掩码和类别概率\n",
    "        object_mask = y_true[l][..., 4:5]\n",
    "        true_class_probs = y_true[l][..., 5:]\n",
    "\n",
    "        # 调用 yolo_head 获取预测框\n",
    "        grid, raw_pred, pred_xy, pred_wh = yolo_head(yolo_outputs[l],\n",
    "                                                     anchors[anchor_mask[l]], num_classes, input_shape, calc_loss=True)\n",
    "        # 合并预测框坐标\n",
    "        pred_box = K.concatenate([pred_xy, pred_wh])\n",
    "\n",
    "        # 处理真实框，计算损失\n",
    "        raw_true_xy = y_true[l][..., :2] * grid_shapes[l][::-1] - grid\n",
    "        raw_true_wh = K.log(y_true[l][..., 2:4] / anchors[anchor_mask[l]] * input_shape[::-1])\n",
    "        raw_true_wh = K.switch(object_mask, raw_true_wh, K.zeros_like(raw_true_wh))  # avoid log(0)=-inf\n",
    "        box_loss_scale = 2 - y_true[l][..., 2:3] * y_true[l][..., 3:4]\n",
    "\n",
    "        # 寻找忽略掩码\n",
    "        ignore_mask = tf.TensorArray(K.dtype(y_true[0]), size=1, dynamic_size=True)\n",
    "        object_mask_bool = K.cast(object_mask, 'bool')\n",
    "\n",
    "        def loop_body(b, ignore_mask):\n",
    "            true_box = tf.boolean_mask(y_true[l][b, ..., 0:4], object_mask_bool[b, ..., 0])\n",
    "            iou = box_iou(pred_box[b], true_box)\n",
    "            best_iou = K.max(iou, axis=-1)\n",
    "            ignore_mask = ignore_mask.write(b, K.cast(best_iou < ignore_thresh, K.dtype(true_box)))\n",
    "            return b + 1, ignore_mask\n",
    "\n",
    "        _, ignore_mask = tf.while_loop(lambda b, *args: b < m, loop_body, [0, ignore_mask])\n",
    "        ignore_mask = ignore_mask.stack()\n",
    "        ignore_mask = K.expand_dims(ignore_mask, -1)\n",
    "\n",
    "        # 计算各部分损失\n",
    "#         xy_loss = object_mask * box_loss_scale * K.binary_crossentropy(raw_true_xy, raw_pred[..., 0:2],\n",
    "#                                                                        from_logits=True)\n",
    "        xy_loss = object_mask * box_loss_scale * 0.5 * K.square(raw_true_xy - raw_pred[..., 0:2])\n",
    "        wh_loss = object_mask * box_loss_scale * 0.5 * K.square(raw_true_wh - raw_pred[..., 2:4])\n",
    "        confidence_loss = object_mask * K.binary_crossentropy(object_mask, raw_pred[..., 4:5], from_logits=True) + \\\n",
    "                          (1 - object_mask) * K.binary_crossentropy(object_mask, raw_pred[..., 4:5],\n",
    "                                                                    from_logits=True) * ignore_mask\n",
    "        class_loss = object_mask * K.binary_crossentropy(true_class_probs, raw_pred[..., 5:], from_logits=True)\n",
    "\n",
    "        # 将每部分损失求和并除以批次大小，实现损失的归一化\n",
    "        xy_loss = K.sum(xy_loss) / mf\n",
    "        wh_loss = K.sum(wh_loss) / mf\n",
    "        confidence_loss = K.sum(confidence_loss) / mf\n",
    "        class_loss = K.sum(class_loss) / mf\n",
    "        # 将所有损失项累加得到总损失\n",
    "        loss += xy_loss + wh_loss + confidence_loss + class_loss\n",
    "        # 如果需要，打印损失信息\n",
    "        if print_loss:\n",
    "            loss = tf.print(loss, [loss, xy_loss, wh_loss, confidence_loss, class_loss, K.sum(ignore_mask)],\n",
    "                            message='loss: ')\n",
    "    # 返回计算得到的总损失\n",
    "    return loss\n",
    "\n",
    "\n",
    "    '''Return yolo_loss tensor\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    yolo_outputs: list of tensor, the output of yolo_body or tiny_yolo_body\n",
    "    y_true: list of array, the output of preprocess_true_boxes\n",
    "    anchors: array, shape=(N, 2), wh\n",
    "    num_classes: integer\n",
    "    ignore_thresh: float, the iou threshold whether to ignore object confidence loss\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loss: tensor, shape=(1,)\n",
    "\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2, weights_path=''):\n",
    "    '''创建用于训练的 YOLOv3 模型\n",
    "    - input_shape: 输入尺寸\n",
    "    - anchors: 锚点\n",
    "    - num_classes: 类别数量\n",
    "    - load_pretrained: 是否加载预训练权重\n",
    "    - freeze_body: 冻结层的模式\n",
    "    - weights_path: 预训练权重的路径\n",
    "    '''\n",
    "\n",
    "    # 定义模型的输入层\n",
    "    image_input = Input(shape=(None, None, 3))\n",
    "    # 获取输入尺寸的高和宽\n",
    "    h, w = input_shape\n",
    "    # 计算锚点数量\n",
    "    num_anchors = len(anchors)\n",
    "\n",
    "    # 定义真实标签的输入层\n",
    "    y_true = [Input(shape=(h // {0: 32, 1: 16, 2: 8}[l], w // {0: 32, 1: 16, 2: 8}[l], num_anchors // 3, num_classes + 5)) for l in range(3)]\n",
    "\n",
    "    # 创建 YOLOv3 模型主体\n",
    "    model_body = yolo_body(image_input, num_anchors // 3, num_classes)\n",
    "    print('Create YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
    "\n",
    "    # 如果需要加载预训练权重\n",
    "    if load_pretrained:\n",
    "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
    "        print('Load weights {}.'.format(weights_path))\n",
    "        # 根据 freeze_body 参数冻结部分层\n",
    "        if freeze_body in [1, 2]:\n",
    "            num = (185, len(model_body.layers) - 3)[freeze_body - 1]\n",
    "            for i in range(num): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
    "\n",
    "    # 创建损失函数层\n",
    "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
    "                        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})(\n",
    "        [*model_body.output, *y_true])\n",
    "    # 构建完整模型\n",
    "    model = Model([model_body.input, *y_true], model_loss)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_data(annotation_line, input_shape, random=False, max_boxes=20):\n",
    "    '''random preprocessing for real-time data augmentation\n",
    "    - annotation_line: 一行标注数据，包含图像路径和边界框信息\n",
    "    - input_shape: 模型输入尺寸\n",
    "    - random: 是否应用随机变换\n",
    "    - max_boxes: 每张图像的最大边界框数量\n",
    "    '''\n",
    "\n",
    "    # 分割标注行，获取图像路径和边界框信息\n",
    "    line = annotation_line.split()\n",
    "    # 打开图像文件\n",
    "    image = Image.open(line[0])\n",
    "    # 获取原始图像尺寸\n",
    "    iw, ih = image.size\n",
    "    # 获取输入尺寸\n",
    "    h, w = input_shape\n",
    "    # 解析边界框数据\n",
    "    box = np.array([np.array(list(map(int, box.split(',')))) for box in line[1:]])\n",
    "\n",
    "    # 计算缩放比例和调整后的图像尺寸\n",
    "    scale = min(w/iw, h/ih)\n",
    "    nw = int(iw*scale)\n",
    "    nh = int(ih*scale)\n",
    "    # 计算图像在新画布上的位置\n",
    "    dx = (w-nw)//2\n",
    "    dy = (h-nh)//2\n",
    "    image_data = 0\n",
    "\n",
    "    # 调整图像尺寸\n",
    "    image = image.resize((nw, nh), Image.BICUBIC)\n",
    "    # 创建新的画布并粘贴调整后的图像\n",
    "    new_image = Image.new('RGB', (w, h), (128, 128, 128))\n",
    "    new_image.paste(image, (dx, dy))\n",
    "    # 将图像转换为模型输入格式\n",
    "    image_data = np.array(new_image)/255.\n",
    "\n",
    "    # 初始化用于训练的边界框数据\n",
    "    box_data = np.zeros((max_boxes, 5))\n",
    "    # 调整边界框坐标\n",
    "    if len(box) > 0:\n",
    "        np.random.shuffle(box)\n",
    "        if len(box) > max_boxes: box = box[:max_boxes]\n",
    "        box[:, [0, 2]] = box[:, [0, 2]] * scale + dx\n",
    "        box[:, [1, 3]] = box[:, [1, 3]] * scale + dy\n",
    "        box_data[:len(box)] = box\n",
    "\n",
    "    # 返回处理后的图像数据和边界框数据\n",
    "    return image_data, box_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_true_boxes(true_boxes, input_shape, anchors, num_classes):\n",
    "    '''Preprocess true boxes to training input format'''\n",
    "\n",
    "    # 检查所有边界框的类别ID是否小于类别总数\n",
    "    assert (true_boxes[..., 4] < num_classes).all(), 'class id must be less than num_classes'\n",
    "    \n",
    "    # 默认设置为3层锚点\n",
    "    num_layers = len(anchors) // 3  \n",
    "    # 设置每层使用的锚点\n",
    "    anchor_mask = [[6, 7, 8], [3, 4, 5], [0, 1, 2]] if num_layers == 3 else [[3, 4, 5], [1, 2, 3]]\n",
    "\n",
    "    # 将真实边界框数据和输入尺寸转换为适当的格式\n",
    "    true_boxes = np.array(true_boxes, dtype='float32')\n",
    "    input_shape = np.array(input_shape, dtype='int32')\n",
    "    \n",
    "    # 计算边界框中心点和宽高\n",
    "    boxes_xy = (true_boxes[..., 0:2] + true_boxes[..., 2:4]) // 2\n",
    "    boxes_wh = true_boxes[..., 2:4] - true_boxes[..., 0:2]\n",
    "    # 将边界框坐标转换为相对于输入尺寸的比例\n",
    "    true_boxes[..., 0:2] = boxes_xy / input_shape[::-1]\n",
    "    true_boxes[..., 2:4] = boxes_wh / input_shape[::-1]\n",
    "\n",
    "    # 初始化 y_true\n",
    "    m = true_boxes.shape[0]\n",
    "    grid_shapes = [input_shape // {0: 32, 1: 16, 2: 8}[l] for l in range(num_layers)]\n",
    "    y_true = [np.zeros((m, grid_shapes[l][0], grid_shapes[l][1], len(anchor_mask[l]), 5 + num_classes),dtype='float32') for l in range(num_layers)]\n",
    "\n",
    "    # 扩展锚点的维度以适应广播\n",
    "    anchors = np.expand_dims(anchors, 0)\n",
    "    anchor_maxes = anchors / 2.\n",
    "    anchor_mins = -anchor_maxes\n",
    "    valid_mask = boxes_wh[..., 0] > 0\n",
    "\n",
    "    for b in range(m):\n",
    "        # 排除无效的行\n",
    "        wh = boxes_wh[b, valid_mask[b]]\n",
    "        if len(wh) == 0: continue\n",
    "        # 扩展维度以适应广播\n",
    "        wh = np.expand_dims(wh, -2)\n",
    "        box_maxes = wh / 2.\n",
    "        box_mins = -box_maxes\n",
    "\n",
    "        intersect_mins = np.maximum(box_mins, anchor_mins)\n",
    "        intersect_maxes = np.minimum(box_maxes, anchor_maxes)\n",
    "        intersect_wh = np.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "        intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "        box_area = wh[..., 0] * wh[..., 1]\n",
    "        anchor_area = anchors[..., 0] * anchors[..., 1]\n",
    "        iou = intersect_area / (box_area + anchor_area - intersect_area)\n",
    "\n",
    "        # 为每个真实边界框找到最匹配的锚点\n",
    "        best_anchor = np.argmax(iou, axis=-1)\n",
    "\n",
    "        for t, n in enumerate(best_anchor):\n",
    "            for l in range(num_layers):\n",
    "                if n in anchor_mask[l]:\n",
    "                    i = np.floor(true_boxes[b, t, 0] * grid_shapes[l][1]).astype('int32')\n",
    "                    j = np.floor(true_boxes[b, t, 1] * grid_shapes[l][0]).astype('int32')\n",
    "                    k = anchor_mask[l].index(n)\n",
    "                    c = true_boxes[b, t, 4].astype('int32')\n",
    "                    # 填充 y_true 张量\n",
    "                    y_true[l][b, j, i, k, 0:4] = true_boxes[b, t, 0:4]\n",
    "                    y_true[l][b, j, i, k, 4] = 1\n",
    "                    y_true[l][b, j, i, k, 5 + c] = 1\n",
    "\n",
    "    return y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    '''data generator for fit_generator\n",
    "    - annotation_lines: 图像的注释行列表，每行包含图像路径和边界框信息\n",
    "    - batch_size: 批次大小\n",
    "    - input_shape: 模型的输入尺寸\n",
    "    - anchors: YOLO模型使用的锚点\n",
    "    - num_classes: 目标类别的总数\n",
    "    '''\n",
    "\n",
    "    # 获取注释行的数量\n",
    "    n = len(annotation_lines)\n",
    "    # 初始化索引\n",
    "    i = 0\n",
    "\n",
    "    # 无限循环，持续生成数据\n",
    "    while True:\n",
    "        # 初始化批次内的图像和边界框列表\n",
    "        image_data = []\n",
    "        box_data = []\n",
    "\n",
    "        # 构建一个批次的数据\n",
    "        for b in range(batch_size):\n",
    "            # 如果索引为0，则随机打乱注释行\n",
    "            if i == 0:\n",
    "                np.random.shuffle(annotation_lines)\n",
    "\n",
    "            # 获取单个图像及其边界框数据\n",
    "            image, box = get_random_data(annotation_lines[i], input_shape, random=False)\n",
    "            # 添加到批次数据列表\n",
    "            image_data.append(image)\n",
    "            box_data.append(box)\n",
    "\n",
    "            # 更新索引，循环使用注释行\n",
    "            i = (i + 1) % n\n",
    "\n",
    "        # 将图像和边界框数据列表转换为NumPy数组\n",
    "        image_data = np.array(image_data)\n",
    "        box_data = np.array(box_data)\n",
    "\n",
    "        # 预处理边界框数据\n",
    "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
    "\n",
    "        # 产出图像数据、标签数据和占位符\n",
    "        yield [image_data, *y_true], np.zeros(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create YOLOv3 model with 9 anchors and 20 classes.\n",
      "WARNING:tensorflow:Skipping loading of weights for layer conv2d_58 due to mismatch in shape ((1, 1, 1024, 75) vs (255, 1024, 1, 1)).\n",
      "WARNING:tensorflow:Skipping loading of weights for layer conv2d_58 due to mismatch in shape ((75,) vs (255,)).\n",
      "WARNING:tensorflow:Skipping loading of weights for layer conv2d_66 due to mismatch in shape ((1, 1, 512, 75) vs (255, 512, 1, 1)).\n",
      "WARNING:tensorflow:Skipping loading of weights for layer conv2d_66 due to mismatch in shape ((75,) vs (255,)).\n",
      "WARNING:tensorflow:Skipping loading of weights for layer conv2d_74 due to mismatch in shape ((1, 1, 256, 75) vs (255, 256, 1, 1)).\n",
      "WARNING:tensorflow:Skipping loading of weights for layer conv2d_74 due to mismatch in shape ((75,) vs (255,)).\n",
      "Load weights yolov3.h5.\n",
      "Freeze the first 249 layers of total 252 layers.\n",
      "Train on 4059 samples, val on 450 samples, with batch size 8.\n",
      "Epoch 1/25\n",
      "507/507 [==============================] - 59s 99ms/step - loss: 686.8931 - val_loss: 39.7856\n",
      "Epoch 2/25\n",
      "507/507 [==============================] - 48s 94ms/step - loss: 36.8385 - val_loss: 31.2308\n",
      "Epoch 3/25\n",
      "507/507 [==============================] - 47s 93ms/step - loss: 30.4225 - val_loss: 27.2752\n",
      "Epoch 4/25\n",
      "507/507 [==============================] - 47s 92ms/step - loss: 27.4803 - val_loss: 26.3845\n",
      "Epoch 5/25\n",
      "507/507 [==============================] - 47s 92ms/step - loss: 25.7425 - val_loss: 24.7107\n",
      "Epoch 6/25\n",
      "507/507 [==============================] - 47s 92ms/step - loss: 24.5535 - val_loss: 23.1658\n",
      "Epoch 7/25\n",
      "507/507 [==============================] - 47s 93ms/step - loss: 23.6432 - val_loss: 23.0214\n",
      "Epoch 8/25\n",
      "507/507 [==============================] - 47s 92ms/step - loss: 23.2667 - val_loss: 22.5518\n",
      "Epoch 9/25\n",
      "507/507 [==============================] - 45s 89ms/step - loss: 22.0143 - val_loss: 21.8015\n",
      "Epoch 10/25\n",
      "507/507 [==============================] - 44s 87ms/step - loss: 21.7025 - val_loss: 21.5108\n",
      "Epoch 11/25\n",
      "507/507 [==============================] - 44s 87ms/step - loss: 21.4802 - val_loss: 21.3084\n",
      "Epoch 12/25\n",
      "507/507 [==============================] - 44s 87ms/step - loss: 20.5367 - val_loss: 20.4844\n",
      "Epoch 13/25\n",
      "507/507 [==============================] - 46s 90ms/step - loss: 20.0711 - val_loss: 20.8848\n",
      "Epoch 14/25\n",
      "507/507 [==============================] - 47s 93ms/step - loss: 20.0218 - val_loss: 20.1790\n",
      "Epoch 15/25\n",
      "507/507 [==============================] - 46s 92ms/step - loss: 19.5004 - val_loss: 19.6067\n",
      "Epoch 16/25\n",
      "507/507 [==============================] - 46s 91ms/step - loss: 19.4143 - val_loss: 20.2779\n",
      "Epoch 17/25\n",
      "507/507 [==============================] - 44s 87ms/step - loss: 19.1554 - val_loss: 20.0822\n",
      "Epoch 18/25\n",
      "507/507 [==============================] - 44s 87ms/step - loss: 18.9613 - val_loss: 19.0281\n",
      "Epoch 19/25\n",
      "507/507 [==============================] - 44s 87ms/step - loss: 18.8677 - val_loss: 20.1495\n",
      "Epoch 20/25\n",
      "507/507 [==============================] - 44s 86ms/step - loss: 18.7650 - val_loss: 18.8040\n",
      "Epoch 21/25\n",
      "507/507 [==============================] - 44s 87ms/step - loss: 18.5654 - val_loss: 19.7688\n",
      "Epoch 22/25\n",
      "507/507 [==============================] - 46s 90ms/step - loss: 18.0290 - val_loss: 18.6161\n",
      "Epoch 23/25\n",
      "507/507 [==============================] - 46s 92ms/step - loss: 18.2977 - val_loss: 19.2053\n",
      "Epoch 24/25\n",
      "507/507 [==============================] - 47s 92ms/step - loss: 18.4356 - val_loss: 19.3574\n",
      "Epoch 25/25\n",
      "507/507 [==============================] - 47s 92ms/step - loss: 18.2376 - val_loss: 19.3942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7d6dd34430>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# anchors = np.array([[10,13], [16,30], [33,23], [30,61], [62,45], [59,119],[116,90], [156,198], [373,326]])\n",
    "# 定义YOLOv3模型的锚点\n",
    "anchors = np.array([[25,39], [38,91], [62,51], [71,136], [123,214], [127,95], [219,293], [250,148], [394,298]])\n",
    "\n",
    "# 定义要检测的类别\n",
    "class_names = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow',\n",
    "               'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "num_classes = len(class_names)  # 类别的数量\n",
    "\n",
    "input_shape = (416, 416)  # 输入尺寸，必须是32的倍数\n",
    "\n",
    "# 创建YOLOv3模型\n",
    "model = create_model(input_shape, anchors, num_classes, freeze_body=2, weights_path='yolov3.h5')\n",
    "\n",
    "# 设置TensorBoard日志\n",
    "logging = TensorBoard(log_dir='logs/')\n",
    "\n",
    "# 设置模型保存的回调函数\n",
    "checkpoint = ModelCheckpoint('ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n",
    "                             monitor='val_loss', save_weights_only=True, save_best_only=True, save_freq=\"epoch\")\n",
    "\n",
    "# 设置学习率衰减的回调函数\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "\n",
    "# 读取训练数据\n",
    "annotation_path = '2007_trainval.txt'\n",
    "val_split = 0.1  # 验证集的比例\n",
    "with open(annotation_path) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# 分割训练集和验证集\n",
    "num_val = int(len(lines) * val_split)\n",
    "num_train = len(lines) - num_val\n",
    "\n",
    "# 编译模型和设置损失函数\n",
    "model.compile(optimizer=Adam(lr=1e-3), loss={'yolo_loss': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "# 打印训练和验证样本数量\n",
    "batch_size = 8\n",
    "print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "\n",
    "# 开始训练模型\n",
    "model.fit(x=data_generator(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "          steps_per_epoch=max(1, num_train // batch_size),\n",
    "          validation_data=data_generator(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "          validation_steps=max(1, num_val // batch_size),\n",
    "          epochs=25,\n",
    "          initial_epoch=0,\n",
    "          callbacks=[logging, checkpoint])  # reduce_lr为可选项\n",
    "\n",
    "# 保存最终的模型\n",
    "# model.save('final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4059 samples, val on 450 samples, with batch size 8.\n",
      "Epoch 26/50\n",
      "507/507 [==============================] - 55s 97ms/step - loss: 17.4452 - val_loss: 18.0984\n",
      "Epoch 27/50\n",
      "507/507 [==============================] - 46s 91ms/step - loss: 16.9324 - val_loss: 18.0666\n",
      "Epoch 28/50\n",
      "507/507 [==============================] - 46s 91ms/step - loss: 16.9438 - val_loss: 18.2090\n",
      "Epoch 29/50\n",
      "507/507 [==============================] - 46s 91ms/step - loss: 16.9735 - val_loss: 17.9186\n",
      "Epoch 30/50\n",
      "507/507 [==============================] - 46s 91ms/step - loss: 16.9865 - val_loss: 17.8229\n",
      "Epoch 31/50\n",
      "507/507 [==============================] - 46s 91ms/step - loss: 16.7233 - val_loss: 18.0692\n",
      "Epoch 32/50\n",
      "507/507 [==============================] - 46s 90ms/step - loss: 17.0337 - val_loss: 17.9939\n",
      "Epoch 33/50\n",
      "507/507 [==============================] - 46s 91ms/step - loss: 16.9882 - val_loss: 17.9747\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 34/50\n",
      "507/507 [==============================] - 46s 91ms/step - loss: 16.8104 - val_loss: 18.3552\n",
      "Epoch 35/50\n",
      "507/507 [==============================] - 46s 91ms/step - loss: 16.5720 - val_loss: 17.7023\n",
      "Epoch 36/50\n",
      "507/507 [==============================] - 46s 92ms/step - loss: 16.7891 - val_loss: 17.6387\n",
      "Epoch 37/50\n",
      "507/507 [==============================] - 46s 91ms/step - loss: 16.8951 - val_loss: 18.0849\n",
      "Epoch 38/50\n",
      "507/507 [==============================] - 46s 91ms/step - loss: 16.8020 - val_loss: 17.9926\n",
      "Epoch 39/50\n",
      "507/507 [==============================] - 46s 91ms/step - loss: 16.7303 - val_loss: 17.8392\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 40/50\n",
      "507/507 [==============================] - 46s 91ms/step - loss: 16.5656 - val_loss: 17.5950\n",
      "Epoch 41/50\n",
      "507/507 [==============================] - 47s 92ms/step - loss: 16.7384 - val_loss: 17.8211\n",
      "Epoch 42/50\n",
      "507/507 [==============================] - 46s 91ms/step - loss: 16.8332 - val_loss: 18.3862\n",
      "Epoch 43/50\n",
      "507/507 [==============================] - 46s 90ms/step - loss: 16.8753 - val_loss: 17.6476\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 44/50\n",
      "507/507 [==============================] - 46s 91ms/step - loss: 16.7201 - val_loss: 18.0904\n",
      "Epoch 45/50\n",
      "507/507 [==============================] - 46s 91ms/step - loss: 17.0371 - val_loss: 18.0045\n",
      "Epoch 46/50\n",
      "507/507 [==============================] - 46s 91ms/step - loss: 16.8557 - val_loss: 17.6004\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "Epoch 47/50\n",
      "507/507 [==============================] - 46s 91ms/step - loss: 16.6440 - val_loss: 18.3916\n",
      "Epoch 48/50\n",
      "507/507 [==============================] - 46s 91ms/step - loss: 16.7627 - val_loss: 17.8158\n",
      "Epoch 49/50\n",
      "507/507 [==============================] - 46s 91ms/step - loss: 16.7053 - val_loss: 18.2101\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
      "Epoch 50/50\n",
      "507/507 [==============================] - 46s 92ms/step - loss: 16.9528 - val_loss: 17.5837\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(lr=1e-4), loss={'yolo_loss': lambda y_true, y_pred: y_pred}) \n",
    "\n",
    "for i in range(len(model.layers)):\n",
    "    model.layers[i].trainable = True\n",
    "\n",
    "batch_size = 8\n",
    "print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "model.fit(  x=data_generator(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "            steps_per_epoch=max(1, num_train // batch_size),\n",
    "            validation_data=data_generator(lines[num_train:], batch_size, input_shape, anchors,num_classes),\n",
    "            validation_steps=max(1, num_val // batch_size),\n",
    "            epochs=50,\n",
    "            initial_epoch=25,\n",
    "            callbacks=[logging, checkpoint,reduce_lr]) #reduce_lr #_generator\n",
    "\n",
    "model.save('final0219.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "2a3fa4898b6df03057227b86708658af4d4b70a995048284f691871c1cf04ab2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
